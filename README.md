# AWS-ETL-YTAnalysis-pyspark-project

Purpose: To extract multiple structured and semi-structured data files in aws, clean the raw data using Python and transform it with a Pyspark job, load the parquet file in the data-lake and create a reporting database for BI analytics.

Services used:
  Amazon S3,
  AWS Lambda,
  AWS Glue,
  AWS Athena


  Dataset Used:
  https://www.kaggle.com/datasets/datasnaek/youtube-new
